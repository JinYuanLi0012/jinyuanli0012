---
layout: homepage
---

## About Me

I am a final-year master's student at [Tianjin University](https://www.tju.edu.cn/english/index.htm), under the mentorship of Prof. [Gang Pan](https://gpantju.github.io/index/). Previously, I worked as a research intern at [Baidu](https://www.paddlepaddle.org.cn/en) and explored multimodal document understanding. I am also fortunate to receive guidance from Prof. [Jianfei Yu](https://sites.google.com/site/jfyu1990/). 

My enthusiasm lies in exploring Multimodal Learning, Vision and Language. My recent series of work ([MNER](https://arxiv.org/pdf/2305.12212)->[GMNER](https://arxiv.org/pdf/2402.09989)->[SMNER](https://arxiv.org/pdf/2406.07268)) explored how to unleash the potential capabilities of visual-language models in complex multimodal scenarios, how to build harmonious interaction and collaboration between multiple models, and how to build knowledge enhancement methods in open-world scenarios. Additionally, I also maintained an interest in several traditional visual tasks ([Blind Image Inpainting](https://jinyuanli0012.github.io/), [Infrared and Visible Image Fusion](https://github.com/NaNagi2020/DSTFuse)). I'm open to collaboration and discussions. Please feel free to contact me and explore possibilities together.

I'm looking for a PhD position starting in Spring/Fall 2025 about Multimodal Learning, Natural Language Processing or Computer Vision. Feel free to contact me if you have any leads~


{% include_relative _includes/Research_Interests.md %}

## NewsðŸ”¥

- **[Jun. 2024]** We release a [new study](https://arxiv.org/abs/2406.07268) proposing the Segmented Multimodal Named Entity Recognition (SMNER) task and constructing the corresponding Twitter-SMNER dataset. Datasets and Code will be released at [here](https://github.com/JinYuanLi0012/RiVEG).
- **[May. 2024]** One paper is accepted to [ACL 2024](https://2024.aclweb.org/). See you in Bangkok!
- **[Apr. 2024]** Delighted to be onboard at Baidu as a research intern.
- **[Feb. 2024]** A new research about Grounded Multimodal Named Entity Recognition (GMNER) and Large Language Models has been released! see [here](https://arxiv.org/abs/2402.09989).
- **[Oct. 2023]** One paper about Multimodal Named Entity Recognition (MNER) is accepted to [EMNLP 2023](https://2023.emnlp.org/).

{% include_relative _includes/publications.md %}

## Experience

- **[Apr. 2024 - Jun. 2024]** [Baidu](https://www.paddlepaddle.org.cn/en), Research Intern


{% include_relative _includes/services.md %}

## Awards and Honors
- **[2022 & 2023]** Second-class Academic Scholarship of Tianjin University
- **[2021]** Merit Student of Taiyuan University of Technology **(<span style="color:red">Top 2%</span>)**
- **[2020 & 2021]** Academic Excellence Scholarship of Taiyuan University of Technology
- **[2020]** Provincial Second Prize in the National College Student Mathematical Modeling Competition
- **[2020]** Excellent Academic Progress Student of Taiyuan University of Technology
- **[2019]** Outstanding Student Cadre of Taiyuan University of Technology

## Miscellaneous
When Iâ€™m not in research mode, I enjoy swimming (Swim one kilometer freestyle in less than 18 minutes) and violin (Fluent sight-reading skills). They have been with me for nearly twenty years. My favorite virtuoso is Ray Chen. His interpretation of the music always carries a distinct personal touch. I hope I can approach my research in the same way.

In the past, I demonstrated strong road cycling capabilities, maintaining a speed of 36 km/h for two hours. Additionally, I found being an anchor very engaging.

To the very best of times.

<div style="display: flex;">
  <img src="/assets/img/LJY_1_new.jpg" alt="Image 1" width="25%" />
  <img src="/assets/img/LJY_5_new.jpg" alt="Image 2" width="25%" />
  <img src="/assets/img/LJY_3_new.jpg" alt="Image 1" width="25%" />
  <img src="/assets/img/LJY_6.jpg" alt="Image 2" width="25%" />
</div>

